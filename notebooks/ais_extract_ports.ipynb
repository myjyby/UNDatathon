{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49f613-b309-4dc2-ae2e-c9bb65b70e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# necessary import functions\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from sedona.register import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9409d1d3-4f42-42bc-86d8-03c2ba37884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port of Djibouti, Djibouti\t11.5890 N\t43.1457 E\n",
    "# Port Said, Egypt\t31.2565 N\t32.2849 E\n",
    "# Port of Alexandria, Egypt\t31.2001 N\t29.9187 E\n",
    "# Entry Point of Suez Canal, Egypt\t30.5852 N\t32.2650 E\n",
    "# Exit Point of Suez Canal, Egypt\t29.9636 N\t32.5618 E\n",
    "# Port of Mombasa, Kenya\t4.0435 S\t39.6668 E\n",
    "# Ports of Madagascar (Toamasina), Madagascar\t18.1429 S\t49.4080 E\n",
    "# Ports of Beira, Mozambique\t19.8286 S\t34.8385 E\n",
    "# Ports of Nacala, Mozambique\t14.5519 S\t40.6725 E\n",
    "# Ports of Maputo, Mozambique\t25.9655 S\t32.5892 E\n",
    "# Port Sudan, Sudan\t19.5903 N\t37.2080 E\n",
    "# Port of Dar es-Salaam, Tanzania\t6.7924 S\t39.2083 E\n",
    "# Chornomorsk,port,UKR,46.3429225,30.6452624\n",
    "# Odesa,port,UKR,46.489814,30.7579897\n",
    "# Yuzhny/Pivdenny,port,UKR,46.6189212,31.0267066\n",
    "# Bosphorus,strait,TUR,41.11833286,29.07183305\n",
    "# Novorossiysk,port,RUS,44.7252759,37.7760587\n",
    "# Sevastopol,port,RUS,44.6216741,33.52471752\n",
    "# Ust-Luga,port,RUS,59.67942354,28.40689607\n",
    "# Vostochny,port,RUS,42.75240645,133.0568527\n",
    "# Primorsk,port,RUS,60.33400206,28.71043499\n",
    "# Murmansk,port,RUS,68.97518069,33.05367146\n",
    "# Taman,port,RUS,45.12601929,36.68152034\n",
    "# St. Petersburg,port,RUS,59.87974862,30.19520534\n",
    "# Vanino,port,RUS,49.08644498,140.2727319\n",
    "# Vladivostok,port,RUS,43.0896029,131.8748952\n",
    "# Sabetta,port,RUS,71.27891484,72.09328074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05cd1f-e44e-436c-88a9-4a8b38fad547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big bbox\n",
    "# latitude min -30 max 32\n",
    "# longitude min 20 max 60\n",
    "\n",
    "# small bbox\n",
    "# latitude min 39 max 50\n",
    "# longitude min 25 max 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62ad97-44fb-4e62-9a2c-d9e59951536a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# save a local CSV from the notebook\n",
    "def create_download_link(query, title=\"Download CSV file\", filename=\"data.csv\"):\n",
    "    start_time = time.monotonic()\n",
    "    df = query.toPandas()\n",
    "    csv = df.to_csv()\n",
    "    # with open(filename, \"w\", encoding=\"utf-8\") as fout:\n",
    "    #     print(csv, file=fout)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload, title=title, filename=filename)\n",
    "    display(f\"{time.monotonic() - start_time}s\")\n",
    "    return HTML(html)\n",
    "\n",
    "# read in UNGP S3 data from a range of dates\n",
    "def get_date_list(basepath, start_date, end_date):\n",
    "    start_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    delta = end_date - start_date\n",
    "    days = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + datetime.timedelta(days=i)\n",
    "        days.append(datetime.datetime.strftime(day, \"%Y-%m-%d\"))\n",
    "    \n",
    "    paths = [basepath + f\"year={day[:4]}/month={day[5:7]}/day={day[8:10]}\" for day in days]\n",
    "    return (paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a9a5c-0407-4626-bd9a-0f06d4707ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# geographic locations\n",
    "# locations = pd.read_csv(\"https://github.com/dhopp1-UNCTAD/ais_helper_files/raw/main/geographic_locations.csv\")\n",
    "locations = pd.read_csv(\"https://raw.githubusercontent.com/UNECE/AIS/master/wpi_12nm_bounding_box_port.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219cea6-f3b6-4ce9-b584-d48ada1eec86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# countries = [\"UA\", \"DJ\", \"EG\", \"KE\", \"MZ\", \"SD\", \"TZ\", \"RU\"]\n",
    "# countries = [\"UA\", \"RU\"]\n",
    "countries = [\"DJ\", \"EG\", \"KE\", \"MZ\", \"SD\", \"TZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389091cf-41d6-4212-8042-58f703f2d784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff5faa-c4a8-41c3-be33-65d4e6c5baf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\" \".join(sorted([f\"{cnt}\" for cnt in locations[\"COUNTRY\"].unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c372d-eaba-4332-9732-99fad7ef3f9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations.loc[locations[\"COUNTRY\"].isna()]  # both are in Namibia I think pandas converted NA into NaN even though it is a str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04cc16-0e2d-4b8c-b2ba-5b3aefde9791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locs = locations.loc[locations[\"COUNTRY\"].isin(countries)][[\"PORT_NAME\", \"COUNTRY\", \"LATITUDE\", \"LONGITUDE\"]].reset_index(drop=True)\n",
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43454e7-f165-470f-80b1-ce447f2b3098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set(locs[\"COUNTRY\"].unique()) == set(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576fcbf7-7307-4ea4-bb79-d476ec13d273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locs[\"name\"] = locs[\"PORT_NAME\"] + \" (\" + locs[\"COUNTRY\"] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900baf8-de99-42e3-a6b8-b4533bea671e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locs[\"longitude\"] = locs[\"LONGITUDE\"]\n",
    "locs[\"latitude\"] = locs[\"LATITUDE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bac5d-4e95-42f2-8ff4-2c459b4771fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bca1f4-4063-414c-a52c-e6340c3c9c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(start_date, end_date, locations, distance_parameter = \"0.3\"):\n",
    "    # distance parameter = 0.01 = 1 kilometer radius\n",
    "    # distance parameter = 0.3 = 30 kilometer radius?\n",
    "    \n",
    "    # big bbox (africa)\n",
    "    # latitude min -30 max 32\n",
    "    # longitude min 20 max 60\n",
    "    bbox_lat_min = -30\n",
    "    bbox_lat_max = 32\n",
    "    bbox_lon_min = 20\n",
    "    bbox_lon_max = 60\n",
    "    \n",
    "    # small bbox (black sea)\n",
    "    # latitude min 39 max 50\n",
    "    # longitude min 25 max 45\n",
    "    # bbox_lat_min = 39\n",
    "    # bbox_lat_max = 50\n",
    "    # bbox_lon_min = 25\n",
    "    # bbox_lon_max = 45\n",
    "\n",
    "    # all geographies in one query\n",
    "    condition_string = \"\"\n",
    "    select_string = \"\"\n",
    "    pos = \"pos\"\n",
    "    for name_i in locations.name:\n",
    "        name_s = name_i.replace('\\'', '')\n",
    "        condition_string += f\"\"\"ST_Contains(ST_Buffer(ST_Point({locations.loc[locations.name == name_i, 'longitude'].values[0]}, {locations.loc[locations.name == name_i, 'latitude'].values[0]}), {distance_parameter}), {pos})\"\"\"\n",
    "        if name_i != locations.name.values[-1]:\n",
    "            condition_string += \" OR \"\n",
    "        if name_i == locations.name.values[0]:\n",
    "            select_string += f\"\"\"CASE WHEN ST_Contains(ST_Buffer(ST_Point({locations.loc[locations.name == name_i, 'longitude'].values[0]}, {locations.loc[locations.name == name_i, 'latitude'].values[0]}), {distance_parameter}), {pos}) THEN '{name_s}' \"\"\"\n",
    "        elif name_i != locations.name.values[-1]:\n",
    "            select_string += f\"\"\"WHEN ST_Contains(ST_Buffer(ST_Point({locations.loc[locations.name == name_i, 'longitude'].values[0]}, {locations.loc[locations.name == name_i, 'latitude'].values[0]}), {distance_parameter}), {pos}) THEN '{name_s}' \"\"\"\n",
    "        else:\n",
    "            select_string += f\"\"\"WHEN ST_Contains(ST_Buffer(ST_Point({locations.loc[locations.name == name_i, 'longitude'].values[0]}, {locations.loc[locations.name == name_i, 'latitude'].values[0]}), {distance_parameter}), {pos}) THEN '{name_s}' \"\"\"\n",
    "            select_string += \"END AS geo_name\"\n",
    "    \n",
    "    # step 1\n",
    "    # read data\n",
    "    basepath = \"s3a://ungp-ais-data-historical-backup/exact-earth-data/transformed/prod/\"\n",
    "    dates = get_date_list(basepath, start_date, end_date)\n",
    "    df = spark.read.parquet(*dates)\n",
    "\n",
    "    # create temp view to be able to use spark SQL\n",
    "    df.createOrReplaceTempView(\"df\")\n",
    "    \n",
    "    # print(spark.sql(\"SELECT * FROM df LIMIT 1\").toPandas().values.tolist())\n",
    "    # print(spark.sql(\"SELECT * FROM df LIMIT 1\").toPandas().columns.tolist())\n",
    "\n",
    "    # adding points and filtering for cargo and tankers\n",
    "    step_01 = spark.sql(f\"\"\"\n",
    "                    SELECT DISTINCT vessel_type, mmsi, date_year, date_month, {select_string} FROM\n",
    "                    (\n",
    "                    SELECT vessel_type, mmsi, date_year, date_month, ST_Point(lon, lat) as pos FROM\n",
    "                    (\n",
    "                        SELECT DISTINCT\n",
    "                            YEAR(dt_pos_utc) as date_year, \n",
    "                            MONTH(dt_pos_utc) AS date_month,\n",
    "                            mmsi, \n",
    "                            vessel_type,\n",
    "                            cast(longitude as Decimal(6,3)) as lon,\n",
    "                            cast(latitude as Decimal(6,3)) as lat\n",
    "                        FROM df\n",
    "                        WHERE vessel_type IN ('Cargo','Tanker') AND (nav_status_code = 1 or nav_status_code = 5)\n",
    "                    ) AS subquery\n",
    "                    WHERE lon >= {bbox_lon_min} AND lon <= {bbox_lon_max} AND lat >= {bbox_lat_min} AND lat <= {bbox_lat_max}\n",
    "                    ) AS subsubquery\n",
    "                    WHERE {condition_string}\n",
    "                    \"\"\")\n",
    "    return (step_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7d5b7-7c59-454d-a281-6e568b466bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries for months\n",
    "# start_month = datetime.datetime.strptime(\"2018-12-01\", \"%Y-%m-%d\")\n",
    "# end_month = datetime.datetime.strptime(\"2020-02-01\", \"%Y-%m-%d\")\n",
    "# start_month = datetime.datetime.strptime(\"2020-03-01\", \"%Y-%m-%d\")\n",
    "# end_month = datetime.datetime.strptime(\"2021-02-01\", \"%Y-%m-%d\")\n",
    "# start_month = datetime.datetime.strptime(\"2021-03-01\", \"%Y-%m-%d\")\n",
    "# end_month = datetime.datetime.strptime(\"2021-07-01\", \"%Y-%m-%d\")\n",
    "# start_month = datetime.datetime.strptime(\"2021-08-01\", \"%Y-%m-%d\")\n",
    "# end_month = datetime.datetime.strptime(\"2022-10-01\", \"%Y-%m-%d\")\n",
    "start_month = datetime.datetime.strptime(\"2022-11-01\", \"%Y-%m-%d\")\n",
    "end_month = datetime.datetime.strptime(\"2023-10-01\", \"%Y-%m-%d\")\n",
    "\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "\n",
    "while start_month <= end_month:\n",
    "    start_dates.append(datetime.datetime.strftime(start_month, \"%Y-%m-%d\"))\n",
    "    end_date = min(start_month + relativedelta(months=1) - relativedelta(days = 1), datetime.datetime.today() - relativedelta(days=2)) # minimum between 2 days ago so don't go ahead of where there are actually files\n",
    "    end_dates.append(datetime.datetime.strftime(end_date, \"%Y-%m-%d\"))\n",
    "    start_month = start_month + relativedelta(months=1)\n",
    "\n",
    "date_dict = {f\"{x}\": None for x in start_dates}\n",
    "\n",
    "for i in range(len(start_dates)):\n",
    "    date_dict[f\"{start_dates[i]}\"] = get_data(start_dates[i], end_dates[i], locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c445f-8c40-4a6f-90cd-938a50191c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix = \"rus_ukr_ships\"\n",
    "prefix = \"black_sea_horn_africa_ships\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223a2b3-d207-4e27-b747-bd8332c1f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick = [\"2022-01-01\", \"2022-02-01\", \"2022-03-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d517f-ff86-441c-b90c-df4869a2e39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for date_str in quick:\n",
    "#     display((prefix, date_str))\n",
    "#     display(create_download_link(date_dict[date_str], filename=f\"{prefix}_{date_str}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ed8e8-0044-40f3-910d-d678b855e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_str, query in date_dict.items():\n",
    "    if date_str in quick:\n",
    "        continue\n",
    "    display((prefix, date_str))\n",
    "    display(create_download_link(query, filename=f\"{prefix}_{date_str}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17546c2-5b00-48b8-9e54-289d2e600a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = [\"UA\", \"DJ\", \"EG\", \"KE\", \"MZ\", \"SD\", \"TZ\", \"RU\", \"ER\", \"SO\", \"YE\"]\n",
    "locations = pd.read_csv(\"https://raw.githubusercontent.com/UNECE/AIS/master/wpi_12nm_bounding_box_port.csv\")\n",
    "locs = locations.loc[locations[\"COUNTRY\"].isin(countries)][[\"PORT_NAME\", \"COUNTRY\", \"LATITUDE\", \"LONGITUDE\"]].reset_index(drop=True)\n",
    "locs[\"name\"] = locs[\"PORT_NAME\"] + \" (\" + locs[\"COUNTRY\"] + \")\"\n",
    "locs[\"longitude\"] = locs[\"LONGITUDE\"]\n",
    "locs[\"latitude\"] = locs[\"LATITUDE\"]\n",
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8cd1b-d5a5-44f0-b517-692fb1a15914",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_locations = pd.DataFrame({\n",
    "    \"name\": [\n",
    "        \"Suez (EG)\",\n",
    "        \"Bosphorus (TR)\",\n",
    "    ],\n",
    "    \"longitude\": [\n",
    "        32.355877,\n",
    "        29.07183305,\n",
    "    ],\n",
    "    \"latitude\": [\n",
    "        30.443370,\n",
    "        41.11833286,\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd765f6-ab06-4c76-a8b2-0da8d40a65ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llocs = pd.concat([locs, s_locations]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d0f08-90b7-41f8-93a8-d9c071b76d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcsv = llocs[[\"name\", \"longitude\", \"latitude\"]].to_csv(index=False)\n",
    "lb64 = base64.b64encode(lcsv.encode())\n",
    "lpayload = lb64.decode()\n",
    "lhtml = f'<a download=\"locs.csv\" href=\"data:text/csv;base64,{lpayload}\" target=\"_blank\">locs.csv</a>'\n",
    "display(HTML(lhtml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fccd7-1638-4f25-ab31-db87a9ddff30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Config template extra",
   "language": "python3",
   "name": "extra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
